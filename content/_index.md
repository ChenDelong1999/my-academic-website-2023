---
# Leave the homepage title empty to use the site title
title: Delong Chen
date: 2022-10-24
type: landing

sections:
  - block: about.avatar
    id: about
    content:
      # Choose a user profile to display (a folder name within `content/authors/`)
      username: admin
  - block: markdown
    id: news
    content:
      title: News
      text: "

      ## **2023**

      ---


**[2023-09-01]**. I started my Ph.D. study at [Hong Kong University of Science and Technology (HKUST)](https://hkust.edu.hk/), supervised by [Prof. Pascale Fung](https://pascale.home.ece.ust.hk/) at the [Center for Artificial Intelligence Research (CAiRE)](https://caire.hkust.edu.hk/).
<br /><br />

**[2023-07-18]**. Our **`Diffusion-Conductor`** is awarded as Best Paper in [AAAI 2023 Inaugural Summer Symposium Series - AI x Metaverse](https://sites.google.com/view/aaai23-ai-x-metaverse/home)! The GAN-based **`Virtual Conductor`** proposed in my bachelor thesis is now upgraded to its diffusion-based version!

  > Zhuoran Zhao, Jinbin Bai, **<u>Delong Chen</u>**, Debang Wang, Yubo Pan<br /> 
  ğŸ¶[**Taming Diffusion Models for Music-driven Conducting Motion Generation**](https://arxiv.org/abs/2306.10065)<br /> 
  In AAAI 2023 Inaugural Summer Symposium Series - AI x Metaverse, 2023 (Best Paper).  [[arxiv]](https://arxiv.org/abs/2306.10065) [[github]](https://github.com/viiika/Diffusion-Conductor) <br /> 


**[2023-06-30]**. Excited to share my latest work done during my internship at Xiaobing.AI -- **`Polite Flamingo`**! During visual instruction tuning of multi-modal LLM, we introduced a multi-modal response rewriter to address the degeneration of response politness, which is a typical instance of the *\"multi-modal alignment tax\"*. Many thanks my great mentors [Baoyuan Wang](https://sites.google.com/site/zjuwby/) (ç‹å®å…ƒ) and [Jianfeng Liu](https://www.linkedin.com/in/jianfeng-liu-9539897b/) (åˆ˜å‰‘é”‹) at Xiaobing.AI, and thanks [Wenliang Dai](https://wenliangdai.github.io/) (æˆ´æ–‡äº®) at HKUST!

  > **<u>Delong Chen</u>**, Jianfeng Liu, Wenliang Dai, Baoyuan Wang<br /> 
  ğŸ¦©[**Visual Instruction Tuning with Polite Flamingo**](https://arxiv.org/abs/2307.01003)<br />
  [[arxiv]](https://arxiv.org/abs/2307.01003) [[github]](https://github.com/ChenDelong1999/polite-flamingo) [[Demo]](http://clever_flamingo.xiaoice.com/)
  <br />


**[2023-06-19]**. We annonce [RemoteCLIP](/publication/arxiv2023remoteclip), the first vision-language foundation model for remote sensing. RemoteCLIP outperform previous image-text retrieval SoTA by 9.14% mean recall on RSICD dataset and by 8.92% on RSICD dataset. For zero-shot classification, our RemoteCLIP outperform CLIP baseline by up to 6.39% average accuracy on 12 downstream datasets. This is a team work with many brilliant grad students at [AIM Group](http://multimodality.group/), thanks Zhangqingyun Guan (ç®¡å¼ é’äº‘), Xiaocong Zhou (å‘¨æ™“èª), Jiale Zhu (æœ±ä½³ä¹), and Wenwen Cai (è”¡é›¯é›¯)!

  > Fan Liu, **<u>Delong Chen</u>** (joint first author), Zhangqingyun Guan, Xiaocong Zhou, Jiale Zhu, Jun Zhou <br /> 
  ğŸ›°ï¸[**RemoteCLIP: Vision-Language Pretraining for Remote Sensing**](https://arxiv.org/abs/2306.11029)<br />
  [[arxiv]](https://arxiv.org/abs/2306.11029) [[github]](https://github.com/ChenDelong1999/RemoteCLIP)<br />
      

**[2023-05-29]**. Our paper \"Few-shot Transfer of Multi-modal Foundational Models: A Survey\" (å¤šæ¨¡æ€å¤§æ¨¡å‹å°æ ·æœ¬è¿ç§»æ–¹æ³•ç ”ç©¶è¿›å±•ç»¼è¿°) is accepted by ChinaMM (ä¸­å›½å¤šåª’ä½“å¤§ä¼š) 2023.

  > å¼ å¤©èˆ’, åˆ˜å‡¡, <u>**é™ˆå¾·é¾™**</u> (âœ‰), ç®¡å¼ é’äº‘, è”¡é›¯é›¯, å‘¨æ™“èª<br />
  ğŸ“—**å¤šæ¨¡æ€å¤§æ¨¡å‹å°æ ·æœ¬è¿ç§»æ–¹æ³•ç ”ç©¶è¿›å±•ç»¼è¿°**<br />
  2023ä¸­å›½å¤šåª’ä½“å¤§ä¼š <br />


**[2023-04-22]**. Our paper of Ensemble Learning with Multi-Order Statistics (**`ELMOS`**) is accepted by IJCAI-23 as oral presentation! Our proposed model achieves SoTA few-shot classification accuracy on  CUB dataset, miniImageNet, tiredImageNet, and CIFAR-FS dataset.
      
  > Sai Yang, Fan Liu, **<u>Delong Chen</u>**, Jun Zhou<br />
  ğŸ”[**Few-shot Classification via Ensemble Learning with Multi-Order Statistics**](https://www.ijcai.org/proceedings/2023/0181.pdf)<br />
  In Proceedings of the 32nd IJCAI, 2023 (oral). [[arxiv]](https://arxiv.org/abs/2305.00454) <br />
      

**[2023-03-11]**. Our works on the Multi-modal E-Commerce Products (MEP-3M) dataset, previously awarded as [IJCAI 2021 LTDL Best Dataset Paper](/publication/icjaiw2021mep/), is now extended and published at [Pattern Recognition](https://www.sciencedirect.com/journal/pattern-recognition).

  > Fan Liu, **<u>Delong Chen</u>** (joint first author), Xiaoyu Du, Ruizhuo Gao, Feng Xu<br />
  ğŸ[**MEP-3M: A large-scale multi-modal E-commerce product dataset**](https://www.sciencedirect.com/science/article/pii/S0031320323002194)<br />
  Pattern Recognition, 2023.<br />


**[2023-03-08]**. I joined Xiaobing.AI (å°å†°) as a research intern, and started to work on multi-modal large language models with [Baoyuan Wang](https://sites.google.com/site/zjuwby/) and [Jianfeng Liu](https://www.linkedin.com/in/jianfeng-liu-9539897b/).
      <br /><br />

## **2022**
      
      ---

**[2022-07-08]**. Our survey paper on Deep Learning Based Single Sample Per Person (SSPP) face recognition is now published in [Artificial Intelligence Review](https://www.springer.com/journal/10462) (IF=12.0). 
      
  > Fan Liu, **<u>Delong Chen</u>** (joint first author), Fei Wang, Zewen Li, Feng Xu<br />
  ğŸ¤–[**Deep learning based single sample face recognition: a survey**](https://link.springer.com/article/10.1007/s10462-022-10240-2)<br />
  Artificial Intelligence Review, 2022


**[2022-06-29]**. My graduation thesis \"Music-driven Conducting Motion Generation based on Motion Decomposition and Self-supervised Cross-modal Perceptual Loss\" [ã€ŠåŸºäºåŠ¨æ€é¢‘åŸŸåˆ†è§£ä¸è·¨æ¨¡æ€æ„ŸçŸ¥çš„ä¹é˜ŸæŒ‡æŒ¥åŠ¨ä½œç”Ÿæˆç³»ç»Ÿã€‹](uploads/é™ˆå¾·é¾™æœ¬ç§‘æ¯•ä¸šè®ºæ–‡_åŸºäºåŠ¨æ€é¢‘åŸŸåˆ†è§£ä¸è‡ªç›‘ç£è·¨æ¨¡æ€æ„ŸçŸ¥çš„ä¹é˜ŸæŒ‡æŒ¥åŠ¨ä½œç”Ÿæˆ.pdf), previously awarded as Outstanding Graduation Thesis of HHU (æ²³æµ·å¤§å­¦ä¼˜ç§€æ¯•ä¸šè®ºæ–‡), is now awarded as the [First Class of Outstanding Graduation Thesis of Jiangsu Province (æ±Ÿè‹çœä¼˜ç§€æ¯•ä¸šè®ºæ–‡ä¸€ç­‰å¥–)](http://jyt.jiangsu.gov.cn/art/2022/6/29/art_58320_10520413.html) !


**[2022-06-23]**. Our work on **`ProtoCILP`** is done at Megvii Technology. We developed a prototype-based approach for improved vision language pretraining, which achieved an +5.81% ImageNet linear probing improvement and an +2.01% ImageNet zero-shot classification improvement compared to CLIP.
      
      
  > **<u>Delong Chen</u>**, Zhao Wu, Fan Liu, Zaiquan Yang, Yixiang Huang, Yiping Bao, Erjin Zhou<br />
  ğŸ“[**ProtoCILP: Prototypical Contrastive Language Image Pretraining**](https://arxiv.org/abs/2206.10996)<br />
  arXiv preprint, 2022. [[arxiv]](https://arxiv.org/abs/2206.10996) [[github]](https://github.com/megvii-research/protoclip)<br />
      

**[2022-03-10]**. Our paper on Music-Driven Conducting Motion Generation is accepted by CCF-B journal [JCST](https://jcst.ict.ac.cn/). The [ConductorMotion100](https://github.com/ChenDelong1999/VirtualConductor/tree/main/ProspectiveCup) dataset has been made public as a track of [The 1st Prospective Cup Meta-Intelligent Data Challenge](http://prospective.tocenet.org/)ï¼ˆé¦–å±Šå›½é™…â€œè¿œè§æ¯â€å…ƒæ™ºèƒ½æ•°æ®æŒ‘æˆ˜å¤§èµ›ï¼‰hold by [Jiangsu Computer Society](https://www.jscs.org.cn/x1.php?id=770)ï¼ˆæ±Ÿè‹çœè®¡ç®—æœºå­¦ä¼šï¼‰.

  > Fan Liu, <u>**Delong Chen**</u> (âœ‰), Ruizhi Zhou, Sai Yang, Feng Xu <br /> 
  ğŸµ[**Self-Supervised Music Motion Synchronization Learning for Music-Driven Conducting Motion Generation**](https://link.springer.com/article/10.1007/s11390-022-2030-z) <br />
  In Journal of Computer Science and Technology (JCST), 2022. [[github]](https://github.com/ChenDelong1999/VirtualConductor) [[video]](https://www.youtube.com/watch?v=8lr5Q2qg58w)

## **2021**

      ---


**[2021-09-22]**. I begin to work at [MEGVII Technology](https://megvii.com/) (æ—·è§†ç ”ç©¶é™¢) as a research intern. My research project is related to multi-modal self-supervised learning and CLIP-style vision-language pretraining.



**[2021-08-21]**. I received a Best Demo Award from [IEEE ICME\'21](http://2021.ieeeicme.org/2021.ieeeicme.org/best_demo_awards.html), a Best Dataset Paper Award from [IJCAI\'21 LTDL workshop](https://ltdl-ijcai21.github.io/submission.html), and a Best Presentation Award from [IEEE BDAI\'21](http://www.bdai.net/2021.html).
      
  > <u>**Delong Chen**</u>, Fan Liu, Zewen Li, Feng Xu <br /> 
  ğŸµ[**VirtualConductor: Music-driven Conducting Video Generation System**](https://arxiv.org/abs/2108.04350) <br />
  In IEEE International Conference on Multimedia and Expo (ICME) 2021 (Best Demo Award). [[arxiv]](https://arxiv.org/abs/2108.04350) [[video]](https://www.bilibili.com/video/BV1aX4y1g7wh) <br />
  <br />
  <u>**Delong Chen**</u>, Fan Liu, Xiaoyu Du, Ruizhuo Gao, Feng Xu<br /> 
  ğŸ[**MEP-3M: A Large-scale Multi-modal E-Commerce Products Dataset**](https://multimodality.group/publication/icjaiw2021mep/MEP_3M__A_Large_scale_Multi_modal_E_Commerce_Dataset.pdf)<br /> 
  In IJCAI 2021 Workshop on Long-Tailed Distribution Learning (LTDL@IJCAI'21) (Best Dataset Paper Award).<br />
  <br />
  <u>**Delong Chen**</u>, Fan Liu, Zheqi Zhang, Xiaomin Lu, Zewen Li <br /> 
  ğŸŒŠ[**Significant Wave Height Prediction based on Wavelet Graph Neural Network**](https://ieeexplore.ieee.org/document/9515293/)<br />
  In 2021 IEEE 4th International Conference on Big Data and Artificial Intelligence (BDAI) (Best Presentation Award). [[arxiv]](https://arxiv.org/abs/2107.09483)<br />
      
      


**[2021-07-01]**. I received my B.S. degree in computer science from [Hohai University (æ²³æµ·å¤§å­¦)](https://en.hhu.edu.cn/) in Nanjing, China, and begin to work as research assistant at the Artificial Intelligence of Multi-modality Group ([AIM Group](https://multimodality.group/)) under the supervision of [Prof. Fan Liu (åˆ˜å‡¡)](https://multimodality.group/author/%E5%88%98%E5%87%A1/).



**[1999-03-19]**. I was born in Shunde, Guangdongï¼ˆå¹¿ä¸œï¼Œé¡ºå¾·ï¼‰, a beautiful city with a lot of delicious food."
    design:
      columns: '2'

  # - block: features
  #   content:
  #     title: Skills
  #     items:
  #       - name: R
  #         description: 90%
  #         icon: r-project
  #         icon_pack: fab
  #       - name: Statistics
  #         description: 100%
  #         icon: chart-line
  #         icon_pack: fas
  #       - name: Photography
  #         description: 10%
  #         icon: camera-retro
  #         icon_pack: fas
  - block: collection
    id: publications
    content:
      count: 100
      title: Publications
      text: |-
        {{% callout note %}}
        See full publication in [Google Scholar](https://scholar.google.com/citations?hl=zh-CN&user=7PW095gAAAAJ&view_op=list_works&sortby=pubdate) or discover relevant content by filtering publications [here](./publication/).
        {{% /callout %}}
      filters:
        folders:
          - publication
        featured_only: true
    design:
      columns: '1'
      view: 5
  # - block: collection
  #   id: publications
  #   content:
  #     count: 100
  #     title: Publications
  #     text: |-
  #       {{% callout note %}}
  #       Quickly discover relevant content by [filtering publications](./publication/).
  #       {{% /callout %}}
  #     filters:
  #       folders:
  #         - publication
  #       exclude_featured: false
  #   design:
  #     columns: '2'
  #     view: 2
  - block: experience
    id: experience
    content:
      title: Experience
      # Date format for experience
      #   Refer to https://wowchemy.com/docs/customization/#date-format
      date_format: Jan 2006
      # Experiences.
      #   Add/remove as many `experience` items below as you like.
      #   Required fields are `title`, `company`, and `date_start`.
      #   Leave `date_end` empty if it's your current employer.
      #   Begin multi-line descriptions with YAML's `|2-` multi-line prefix.
      items:
        - title: Ph.D. Student
          company: Hong Kong University of Science and Technology (HKUST)
          company_url: 'https://hkust.edu.hk/'
          company_logo: ''
          location: Hong Kong
          date_start: '2023-09-01'
          date_end: ''
          description: 'Supervisor: Prof. Pascale Fung'

        - title: Research Intern
          company: Xiaobing.AI (XiaoIce/å°å†°)
          company_url: 'https://www.xiaoice.com/'
          company_logo: ''
          location: Beijing
          date_start: '2023-03-01'
          date_end: ''
          description: Multi-modal Large Language Models, Conversational AI
        
        - title: Research Intern
          company: Megvii Research (æ—·è§†ç ”ç©¶é™¢)
          company_url: 'https://en.megvii.com/'
          company_logo: ''
          location: Beijing
          date_start: '2021-09-01'
          date_end: '2022-09-01'
          description: Large-scale vision-language pretraining

        - title: Research Assistant
          company: AIM Group, Hohai University (æ²³æµ·å¤§å­¦å¤šæ¨¡æ€äººå·¥æ™ºèƒ½å®éªŒå®¤)
          company_url: 'https://multimodality.group'
          company_logo: ''
          location: Nanjing (Remote)
          date_start: '2021-09-01'
          date_end: '2023-09-01'
          description: |2-
              Lead a team of graduate students working on research projects include:
              * Vision-language learning for earth observations (satellite and UAV images)
              * Few-shot learning for visual recognition
              * Hydrological time-series forecasting
              * Music-motion pretraining for beat tracking
        
        - title: Orchestra Leader and Concert Master
          company: Symphony Orchestra of Hohai University (æ²³æµ·å¤§å­¦ç®¡å¼¦ä¹å›¢)
          company_url: ''
          company_logo: 
          location: Nanjing
          date_start: '2019-05-01'
          date_end: '2020-09-01'
          description: 

        - title: Summer Program
          company: The University of British Columbia (UBC)
          company_url: 'https://www.ubc.ca/'
          company_logo: ''
          location: Vancuver, Canada
          date_start: '2018-07-15'
          date_end: '2021-08-15'
          description: |2-
              Two Courses Taken
              * Computation for Natural Language Processing (scored 97/100)
              * Linguistics for Natural Language Processing (scored 85/100)

        - title: Undergraduate Study
          company: Hohai University (æ²³æµ·å¤§å­¦)
          company_url: 'https://en.hhu.edu.cn/'
          company_logo: ''
          location: Nanjing
          date_start: '2017-09-01'
          date_end: '2021-06-01'
          description: |2-
            * Bachelor of Science degree in Computer Science
            * Excellent Graduate Student
            * First-class Outstanding Graduation Thesis of Jiangsu Province
    design:
      columns: '2'
  # - block: accomplishments
  #   content:
  #     # Note: `&shy;` is used to add a 'soft' hyphen in a long heading.
  #     title: 'Accomplish&shy;ments'
  #     subtitle:
  #     # Date format: https://wowchemy.com/docs/customization/#date-format
  #     date_format: Jan 2006
  #     # Accomplishments.
  #     #   Add/remove as many `item` blocks below as you like.
  #     #   `title`, `organization`, and `date_start` are the required parameters.
  #     #   Leave other parameters empty if not required.
  #     #   Begin multi-line descriptions with YAML's `|2-` multi-line prefix.
  #     items:
  #       - certificate_url: https://www.coursera.org
  #         date_end: ''
  #         date_start: '2021-01-25'
  #         description: ''
  #         organization: Coursera
  #         organization_url: https://www.coursera.org
  #         title: Neural Networks and Deep Learning
  #         url: ''
  #       - certificate_url: https://www.edx.org
  #         date_end: ''
  #         date_start: '2021-01-01'
  #         description: Formulated informed blockchain models, hypotheses, and use cases.
  #         organization: edX
  #         organization_url: https://www.edx.org
  #         title: Blockchain Fundamentals
  #         url: https://www.edx.org/professional-certificate/uc-berkeleyx-blockchain-fundamentals
  #       - certificate_url: https://www.datacamp.com
  #         date_end: '2020-12-21'
  #         date_start: '2020-07-01'
  #         description: ''
  #         organization: DataCamp
  #         organization_url: https://www.datacamp.com
  #         title: 'Object-Oriented Programming in R'
  #         url: ''
  #   design:
  #     columns: '2'
  # - block: collection
  #   id: posts
  #   content:
  #     title: Recent Posts
  #     subtitle: ''
  #     text: ''
  #     # Choose how many pages you would like to display (0 = all pages)
  #     count: 5
  #     # Filter on criteria
  #     filters:
  #       folders:
  #         - post
  #       author: ""
  #       category: ""
  #       tag: ""
  #       exclude_featured: false
  #       exclude_future: false
  #       exclude_past: false
  #       publication_type: ""
  #     # Choose how many pages you would like to offset by
  #     offset: 0
  #     # Page order: descending (desc) or ascending (asc) date.
  #     order: desc
  #   design:
  #     # Choose a layout view
  #     view: compact
  #     columns: '2'
  - block: markdown
    id: awards
    content:
      title: Selected awards, prizes, and honors
      text: "

- **2023-01.**	**Best Paper Award** at AAAI 2023 Inaugural Summer Symposium Series - AI x Metaverse
  <br /><br />

- **2022-06.**	æ±Ÿè‹çœä¼˜ç§€æœ¬ç§‘æ¯•ä¸šè®ºæ–‡ä¸€ç­‰å¥– 
  <br /> **First Class Outstanding Graduation Thesis** of Jiangsu Province
  <br /><br />

- **2021-08.**	**Best Dataset Paper Award** at Long-Tailed Distribution Learning Workshop, IJCAI 2021
  <br /><br />

- **2021-07.**	**Best Demo Award** at IEEE International Conference on Multimedia and Expo (ICME) 2021
  <br /><br />

- **2021-07.**	**Best Presentation Winner** at 2021 4th International Conference on Big Data and Artificial Intelligence
  <br /><br />

- **2021-06.**	æ²³æµ·å¤§å­¦2021å±Šæœ¬ç§‘ä¼˜ç§€æ¯•ä¸šè®¾è®¡ 
  <br /> **Outstanding Graduation Thesis** of Hohai University in 2021
  <br /><br />

- **2021-06.** æ²³æµ·å¤§å­¦2021å±Šæœ¬ç§‘â€œä¼˜ç§€æ¯•ä¸šç”Ÿâ€è£èª‰ç§°å· 
  <br /> 	Excellent Graduate Student of Hohai University (highest honor)
  <br /><br />

- **2021-04.** 2020æ±Ÿè‹çœå¤§å­¦ç”Ÿç½‘ç»œæ–‡åŒ–èŠ‚æ ¡å›­æ­Œæ›²ä½œå“å¾é›†ä¸€ç­‰å¥– 
  <br /> 	First Prize in 2020 Campus Music Competition of Jiangsu Province
  <br /><br />

- **2020-05.**	â€œæ±Ÿè‹çœä¼˜ç§€å…±é’å›¢å‘˜â€ç§°å· 
  <br /> Excellent Communist Youth League Member of Jiangsu Province
  <br /><br />

- **2020-10.**	â€œ2019æ±Ÿè‹çœå¤§å­¦ç”Ÿå¹´åº¦äººç‰©â€æåå¥– 
  <br /> Nomination Award for the Person of the Year in Jiangsu Province in 2019
  <br /><br />

- **2020-04.**	2020å¹´æ²³æµ·å¤§å­¦â€œæµ·éŸµé£åå¤§å­¦ç”Ÿå¹´åº¦äººç‰©â€ç§°å· 
  <br /> Hohai University's 2019 Undergraduate Person of the Year
  <br /><br />

- **2019-06.**	ç¬¬å…«å±Šâ€œä¸­å›½è½¯ä»¶æ¯â€å¤§å­¦ç”Ÿè½¯ä»¶è®¾è®¡å¤§èµ›åä¸œåˆ†èµ›åŒºå†³èµ›ä¸‰ç­‰å¥–ï¼Œå›¢é˜Ÿè´Ÿè´£äºº 
  <br /> Third Prize of The 8th China Software Cup Competition, East China Division Finals (team Leader)
  <br /><br />

- **2017-10.**	æ²³æµ·å¤§å­¦è®¡ç®—æœºä¸ä¿¡æ¯å­¦é™¢2017å¹´æ–°ç”Ÿæ¯è¾©è®ºèµ›â€œæœ€ä½³è¾©æ‰‹â€ç§°å· 
  <br /> Best Debater in the 2017 Freshman Cup Debate Competition of the School of Computer and Information, Hohai University	Aug. 2021
  <br /><br />
"
    design:
      # Choose a layout view
      view: compact
      columns: '2'
  - block: portfolio
    id: music
    content:
      title: MusicğŸ»
      filters:
        folders:
          - project
      # Default filter index (e.g. 0 corresponds to the first `filter_button` instance below).
      default_button_index: 0
      # Filter toolbar (optional).
      # Add or remove as many filters (`filter_button` instances) as you like.
      # To show all items, set `tag` to "*".
      # To filter by a specific tag, set `tag` to an existing tag name.
      # To remove the toolbar, delete the entire `filter_button` block.
      # buttons:
      #   - name: All
      #     tag: '*'
      #   - name: Deep Learning
      #     tag: Deep Learning
      #   - name: Other
      #     tag: Demo
    design:
      # Choose how many columns the section has. Valid values: '1' or '2'.
      columns: '1'
      view: 0
      # For Showcase view, flip alternate rows?
      flip_alt_rows: false
  - block: markdown
    id: gallery
    content:
      title: Gallery
      subtitle: ''
      text: |-
        {{< gallery album="demo" >}}
    design:
      columns: '1'

  # - block: collection
  #   id: talks
  #   content:
  #     title: Recent & Upcoming Talks
  #     filters:
  #       folders:
  #         - event
  #   design:
  #     columns: '2'
  #     view: compact
  # - block: tag_cloud
  #   content:
  #     title: Popular Topics
  #   design:
  #     columns: '2'
  # - block: contact
  #   id: contact
  #   content:
  #     title: Contact
  #     subtitle:
  #     text: |-
  #       Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam mi diam, venenatis ut magna et, vehicula efficitur enim.
  #     # Contact (add or remove contact options as necessary)
  #     email: test@example.org
  #     phone: 888 888 88 88
  #     appointment_url: 'https://calendly.com'
  #     address:
  #       street: 450 Serra Mall
  #       city: Stanford
  #       region: CA
  #       postcode: '94305'
  #       country: United States
  #       country_code: US
  #     directions: Enter Building 1 and take the stairs to Office 200 on Floor 2
  #     office_hours:
  #       - 'Monday 10:00 to 13:00'
  #       - 'Wednesday 09:00 to 10:00'
  #     contact_links:
  #       - icon: twitter
  #         icon_pack: fab
  #         name: DM Me
  #         link: 'https://twitter.com/Twitter'
  #       - icon: skype
  #         icon_pack: fab
  #         name: Skype Me
  #         link: 'skype:echo123?call'
  #       - icon: video
  #         icon_pack: fas
  #         name: Zoom Me
  #         link: 'https://zoom.com'
  #     # Automatically link email and phone or display as text?
  #     autolink: true
  #     # Email form provider
  #     form:
  #       provider: netlify
  #       formspree:
  #         id:
  #       netlify:
  #         # Enable CAPTCHA challenge to reduce spam?
  #         captcha: false
  #   design:
  #     columns: '2'
---
