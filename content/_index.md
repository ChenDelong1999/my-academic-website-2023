---
# Leave the homepage title empty to use the site title
title: Delong Chen
date: 2023-10-17
type: landing

sections:
  - block: about.avatar
    id: about
    content:
      # Choose a user profile to display (a folder name within `content/authors/`)
      username: admin
  - block: markdown
    id: news
    content:
      title: News 🚀
      text: "

 

<div id='title-2023' style='width:auto;height:auto;background-color: transparent;' onclick='onTileClick_2023 ()'>
<h2>&#9660 2023</h2>
</div>
<div id='news-2023' style='width:auto;overflow: hidden;height:auto;background-color: transparent;transition: height 1.0s;'>


      ---


**[2023-09-21]**. Happy to share the latest work collaborated with Xinyu Zhou (周欣宇) <font color='red'>❤</font>. We study the potential of building a unified spoken-dialogue system based on large language models, thus enabling AI chatbots to “think how to respond” and “think how to speak” at the same time!

  > <font size=2>[Xinyu Zhou](https://www.linkedin.com/in/xinyu-zhou2000/), **<u>Delong Chen</u>**, [Yudong Chen](https://rwxy.cuc.edu.cn/2019/0730/c5134a133504/pagem.htm)<br /> 
  🎙 [**Towards Joint Modeling of Dialogue Response and Speech Synthesis based on Large Language Model**](https://arxiv.org/abs/2309.11000)<br /> 
  International Conference on Natural Language and Speech Processing (ICNLSP) 2023. [[arxiv]](https://arxiv.org/abs/2309.11000) [[github]](https://github.com/XinyuZhou2000/Spoken_Dialogue) <br /></font>


{{% callout note %}}
**[2023-09-01]**.  I started my Ph.D. study at Hong Kong University of Science and Technology (HKUST) supervised by [Prof. Pascale Fung](https://pascale.home.ece.ust.hk/).
{{% /callout %}}

**[2023-07-18]**. Our **`Diffusion-Conductor`** is awarded as Best Paper in [AAAI 2023 Inaugural Summer Symposium Series - AI x Metaverse](https://sites.google.com/view/aaai23-ai-x-metaverse/home)! The GAN-based **`Virtual Conductor`** proposed in my bachelor thesis is now upgraded to its diffusion-based version!

  > <font size=2>[Zhuoran Zhao](https://alicezrzhao.github.io/), [Jinbin Bai](https://noyii.github.io/), **<u>Delong Chen</u>**, Debang Wang, Yubo Pan<br /> 
  🎶 [**Taming Diffusion Models for Music-driven Conducting Motion Generation**](https://arxiv.org/abs/2306.10065)<br /> 
  In AAAI 2023 Inaugural Summer Symposium Series - AI x Metaverse, 2023 <font color='red'>**(Best Paper)**</font>.  [[arxiv]](https://arxiv.org/abs/2306.10065) [[github]](https://github.com/viiika/Diffusion-Conductor) <br /></font>



**[2023-06-30]**. Excited to share my latest work done during my internship at Xiaobing.AI -- **`Polite Flamingo`**! During visual instruction tuning of multi-modal LLM, we introduced a multi-modal response rewriter to address the degeneration of response politness, which is a typical instance of the \"multi-modal alignment tax\". Many thanks my great mentors [Baoyuan Wang](https://sites.google.com/site/zjuwby/) (王宝元) and [Jianfeng Liu](https://www.linkedin.com/in/jianfeng-liu-9539897b/) (刘剑锋) at Xiaobing.AI, and [Wenliang Dai](https://wenliangdai.github.io/) (戴文亮) at HKUST!

  > <font size=2>**<u>Delong Chen</u>**, [Jianfeng Liu]((https://www.linkedin.com/in/jianfeng-liu-9539897b/)), [Wenliang Dai](https://wenliangdai.github.io/), [Baoyuan Wang](https://sites.google.com/site/zjuwby/)<br /> 
  🦩 [**Visual Instruction Tuning with Polite Flamingo**](https://arxiv.org/abs/2307.01003)<br />
  [[arxiv]](https://arxiv.org/abs/2307.01003) [[github]](https://github.com/ChenDelong1999/polite-flamingo) [[Demo]](http://clever_flamingo.xiaoice.com/)
  <br /></font>


**[2023-06-19]**. We annonce **`RemoteCLIP`**, the first vision-language foundation model for remote sensing. **`RemoteCLIP`** outperform previous image-text retrieval SoTA by 9.14% mean recall on RSICD dataset and by 8.92% on RSICD dataset. For zero-shot classification, our **`RemoteCLIP`** outperform CLIP baseline by up to 6.39% average accuracy on 12 downstream datasets. This is a team work with many brilliant grad students at [AIM Group](http://multimodality.group/), thanks Zhangqingyun Guan (管张青云), Xiaocong Zhou (周晓聪), Jiale Zhu (朱佳乐), and Wenwen Cai (蔡雯雯)!

  > <font size=2>[Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), **<u>Delong Chen</u>** (joint first author), Zhangqingyun Guan, Xiaocong Zhou, Jiale Zhu, [Jun Zhou](https://experts.griffith.edu.au/7205-jun-zhou) <br /> 
  🛰️ [**RemoteCLIP: Vision-Language Pretraining for Remote Sensing**](https://arxiv.org/abs/2306.11029)<br />
  [[arxiv]](https://arxiv.org/abs/2306.11029) [[github]](https://github.com/ChenDelong1999/RemoteCLIP)<br /></font>
      

<!-- **[2023-05-29]**. Our paper \"Few-shot Transfer of Multi-modal Foundational Models: A Survey\" (多模态大模型小样本迁移方法研究进展综述) is accepted by ChinaMM (中国多媒体大会) 2023.

  > <font size=2>张天舒, 刘凡, <u>**陈德龙**</u> (✉), 管张青云, 蔡雯雯, 周晓聪<br />
  📗 **多模态大模型小样本迁移方法研究进展综述**<br />
  2023中国多媒体大会 <br /></font> -->


**[2023-04-22]**. Our paper of Ensemble Learning with Multi-Order Statistics (**`ELMOS`**) is accepted by IJCAI-23 as oral presentation! Our proposed model achieves SoTA few-shot classification accuracy on  CUB dataset, miniImageNet, tiredImageNet, and CIFAR-FS dataset.
      
  > <font size=2>Sai Yang, [Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), **<u>Delong Chen</u>**, [Jun Zhou](https://experts.griffith.edu.au/7205-jun-zhou)<br />
  🔍 [**Few-shot Classification via Ensemble Learning with Multi-Order Statistics**](https://www.ijcai.org/proceedings/2023/0181.pdf)<br />
  In Proceedings of the 32nd IJCAI, 2023 <font color='red'>**(oral)**</font>. [[arxiv]](https://arxiv.org/abs/2305.00454) <br /></font>
      

**[2023-03-11]**. Our works on the Multi-modal E-Commerce Products (**`MEP-3M`**) dataset, previously awarded as [IJCAI 2021 LTDL Best Dataset Paper](/publication/icjaiw2021mep/), is now extended and published at [Pattern Recognition](https://www.sciencedirect.com/journal/pattern-recognition).

  > <font size=2>[Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), **<u>Delong Chen</u>** (joint first author), [Xiaoyu Du](https://bio.duxy.cc/), Ruizhuo Gao, [Feng Xu](https://www.hhu.edu.cn/2021/0915/c15750a227946/page.htm)<br />
  🎁 [**MEP-3M: A large-scale multi-modal E-commerce product dataset**](https://www.sciencedirect.com/science/article/pii/S0031320323002194)<br />
  Pattern Recognition, 2023.<br /></font>


{{% callout note %}}
**[2023-03-08]**. I joined Xiaobing.AI (小冰) as a research intern, and started to work on multi-modal large language models with [Baoyuan Wang](https://sites.google.com/site/zjuwby/) and [Jianfeng Liu](https://www.linkedin.com/in/jianfeng-liu-9539897b/).
{{% /callout %}}



</div>

<script type='text/javascript'>
var content_2023 = document.getElementById('news-2023');
var title_2023 = document.getElementById('title-2023');
function onTileClick_2023() {
    if (content_2023.style.height === '0px') {
        content_2023.style.height = 'auto';
        title_2023.innerHTML = '<h2>&#9660; 2023</h2>';
    } else {
        content_2023.style.height = '0px';
        title_2023.innerHTML = '<h2>&#9654; 2023</h2>';
    }
}
</script>

 
<div id='title-2022' style='width:auto;height:auto;background-color: transparent;' onclick='onTileClick_2022 ()'>
<h2>▶ 2022</h2>
</div>
<div id='news-2022' style='width:auto;overflow: hidden;height:0;background-color: transparent;transition: height 1.0s;'>


      ---


**[2022-07-08]**. Our survey paper on Deep Learning Based Single Sample Per Person (SSPP) face recognition is now published in [Artificial Intelligence Review](https://www.springer.com/journal/10462) (IF=12.0). 
      
  > <font size=2>[Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), **<u>Delong Chen</u>** (joint first author), Fei Wang, [Zewen Li](https://zewenli.cn/), [Feng Xu](https://www.hhu.edu.cn/2021/0915/c15750a227946/page.htm)<br />
  🤖 [**Deep learning based single sample face recognition: a survey**](https://link.springer.com/article/10.1007/s10462-022-10240-2)<br />
  Artificial Intelligence Review, 2022</font>


**[2022-06-29]**. My bachelor graduation thesis \"Music-driven Conducting Motion Generation based on Motion Decomposition and Self-supervised Cross-modal Perceptual Loss\" [《基于动态频域分解与跨模态感知的乐队指挥动作生成系统》](uploads/陈德龙本科毕业论文_基于动态频域分解与自监督跨模态感知的乐队指挥动作生成.pdf), previously awarded as Outstanding Graduation Thesis of HHU (河海大学优秀毕业论文), is now awarded as the [First Class of Outstanding Graduation Thesis of Jiangsu Province (江苏省优秀毕业论文一等奖)](http://jyt.jiangsu.gov.cn/art/2022/6/29/art_58320_10520413.html) !


**[2022-06-23]**. Our work on **`ProtoCILP`** is done at Megvii Technology. We developed a prototype-based approach for improved vision language pretraining, which achieved an +5.81% ImageNet linear probing improvement and an +2.01% ImageNet zero-shot classification improvement compared to CLIP.
      
      
  > <font size=2>**<u>Delong Chen</u>**, Zhao Wu, [Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), Zaiquan Yang, [Yixiang Huang](https://scholar.google.com/citations?user=YgEsuO0AAAAJ&hl=en), Yiping Bao, [Erjin Zhou](https://scholar.google.com/citations?user=k2ziPUsAAAAJ&hl=en)<br />
  📍 [**ProtoCILP: Prototypical Contrastive Language Image Pretraining**](https://arxiv.org/abs/2206.10996)<br />
  arXiv preprint, 2022. [[arxiv]](https://arxiv.org/abs/2206.10996) [[github]](https://github.com/megvii-research/protoclip)<br /></font>
      

**[2022-03-10]**. Our paper on Music-Driven Conducting Motion Generation is accepted by CCF-B journal [JCST](https://jcst.ict.ac.cn/). The [ConductorMotion100](https://github.com/ChenDelong1999/VirtualConductor/tree/main/ProspectiveCup) dataset has been made public as a track of [The 1st Prospective Cup Meta-Intelligent Data Challenge](http://prospective.tocenet.org/)（首届国际“远见杯”元智能数据挑战大赛）hold by [Jiangsu Computer Society](https://www.jscs.org.cn/x1.php?id=770)（江苏省计算机学会）.

  > <font size=2>[Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), <u>**Delong Chen**</u> (✉), Ruizhi Zhou, Sai Yang, [Feng Xu](https://www.hhu.edu.cn/2021/0915/c15750a227946/page.htm) <br /> 
  🎵 [**Self-Supervised Music Motion Synchronization Learning for Music-Driven Conducting Motion Generation**](https://link.springer.com/article/10.1007/s11390-022-2030-z) <br />
  In Journal of Computer Science and Technology (JCST), 2022. [[github]](https://github.com/ChenDelong1999/VirtualConductor) [[video]](https://www.youtube.com/watch?v=8lr5Q2qg58w)</font>

</div>

<script type='text/javascript'>
var content_2022 = document.getElementById('news-2022');
var title_2022 = document.getElementById('title-2022');
function onTileClick_2022() {
    if (content_2022.style.height === '0px') {
        content_2022.style.height = 'auto';
        title_2022.innerHTML = '<h2>&#9660; 2022</h2>';
    } else {
        content_2022.style.height = '0px';
        title_2022.innerHTML = '<h2>&#9654; 2022</h2>';
    }
}
</script>
 

 
<div id='title-2021' style='width:auto;height:auto;background-color: transparent;' onclick='onTileClick_2021 ()'>
<h2>&#9654; 2021</h2>
</div>
<div id='news-2021' style='width:auto;overflow: hidden;height:0;background-color: transparent;transition: height 1.0s;'>


      ---

**[2021-09-22]**. I begin to work at [MEGVII Technology](https://megvii.com/) (旷视研究院) as a research intern with [Yiping Bao](https://scholar.google.com/citations?hl=zh-CN&user=EB9_W4kAAAAJ) (鲍一平) and [Zhao Wu](https://scholar.google.com/citations?hl=zh-CN&user=rhIsGusAAAAJ) (吴曌).


**[2021-08-21]**. I received a Best Demo Award from [IEEE ICME\'21](http://2021.ieeeicme.org/2021.ieeeicme.org/best_demo_awards.html), a Best Dataset Paper Award from [IJCAI\'21 LTDL workshop](https://ltdl-ijcai21.github.io/submission.html), and a Best Presentation Award from [IEEE BDAI\'21](http://www.bdai.net/2021.html).
      
  > <font size=2><u>**Delong Chen**</u>, [Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), [Zewen Li](https://zewenli.cn/), [Feng Xu](https://www.hhu.edu.cn/2021/0915/c15750a227946/page.htm) <br /> 
  🎵 [**VirtualConductor: Music-driven Conducting Video Generation System**](https://arxiv.org/abs/2108.04350) <br />
  In IEEE International Conference on Multimedia and Expo (ICME) 2021 <font color='red'>**(Best Demo Award)**</font>. [[arxiv]](https://arxiv.org/abs/2108.04350) [[video]](https://www.bilibili.com/video/BV1aX4y1g7wh) <br />
  <br />
  <u>**Delong Chen**</u>, [Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), [Xiaoyu Du](https://bio.duxy.cc/), Ruizhuo Gao, [Feng Xu](https://www.hhu.edu.cn/2021/0915/c15750a227946/page.htm)<br /> 
  🎁 [**MEP-3M: A Large-scale Multi-modal E-Commerce Products Dataset**](https://multimodality.group/publication/icjaiw2021mep/MEP_3M__A_Large_scale_Multi_modal_E_Commerce_Dataset.pdf)<br /> 
  In IJCAI 2021 Workshop on Long-Tailed Distribution Learning (LTDL@IJCAI'21) <font color='red'>**(Best Dataset Paper Award)**</font>.<br />
  <br />
  <u>**Delong Chen**</u>, [Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/), Zheqi Zhang, Xiaomin Lu, [Zewen Li](https://zewenli.cn/) <br /> 
  🌊 [**Significant Wave Height Prediction based on Wavelet Graph Neural Network**](https://ieeexplore.ieee.org/document/9515293/)<br />
  In 2021 IEEE 4th International Conference on Big Data and Artificial Intelligence <font color='red'>**(Best Presentation)**</font>. [[arxiv]](https://arxiv.org/abs/2107.09483)<br /></font>
      
      

{{% callout note %}}
**[2021-07-01]**. I received my Bachelor degree in computer science from [Hohai University (河海大学)](https://en.hhu.edu.cn/) in Nanjing, China, and begin to work as research assistant at the Artificial Intelligence of Multi-modality Group ([AIM Group](https://multimodality.group/)) under the supervision of [Prof. Fan Liu (刘凡)](https://multimodality.group/author/%E5%88%98%E5%87%A1/).
{{% /callout %}}



**[1999-03-19]**. I was born in Shunde, Guangdong（广东，顺德）, a beautiful city with a lot of delicious food.


</div>

<script type='text/javascript'>
var content_2021 = document.getElementById('news-2021');
var title_2021 = document.getElementById('title-2021');
function onTileClick_2021() {
    if (content_2021.style.height === '0px') {
        content_2021.style.height = 'auto';
        title_2021.innerHTML = '<h2>&#9660; 2021</h2>';
    } else {
        content_2021.style.height = '0px';
        title_2021.innerHTML = '<h2>&#9654; 2021</h2>';
    }
}
</script>

"
    design:
      columns: '2'

  # - block: features
  #   content:
  #     title: Skills
  #     items:
  #       - name: R
  #         description: 90%
  #         icon: r-project
  #         icon_pack: fab
  #       - name: Statistics
  #         description: 100%
  #         icon: chart-line
  #         icon_pack: fas
  #       - name: Photography
  #         description: 10%
  #         icon: camera-retro
  #         icon_pack: fas
  - block: collection
    id: publications
    content:
      count: 100
      title: Selected Publications ⭐
      subtitle: ''
      text: |-
        {{% callout %}}
        See full publication list in [**this page**](./publication/) or in [**Google Scholar**](https://scholar.google.com/citations?hl=zh-CN&user=7PW095gAAAAJ&view_op=list_works&sortby=pubdate).
        {{% /callout %}}
      filters:
        folders:
          - publication
        featured_only: true
    design:
      columns: '1'
      view: 5
  # - block: collection
  #   id: publications
  #   content:
  #     count: 100
  #     title: Publications
  #     text: |-
  #       {{% callout note %}}
  #       Quickly discover relevant content by [filtering publications](./publication/).
  #       {{% /callout %}}
  #     filters:
  #       folders:
  #         - publication
  #       exclude_featured: false
  #   design:
  #     columns: '2'
  #     view: 2
  - block: experience
    id: experience
    content:
      title: Experience 🎓
      subtitle: ''
      # Date format for experience
      #   Refer to https://wowchemy.com/docs/customization/#date-format
      date_format: Jan 2006
      # Experiences.
      #   Add/remove as many `experience` items below as you like.
      #   Required fields are `title`, `company`, and `date_start`.
      #   Leave `date_end` empty if it's your current employer.
      #   Begin multi-line descriptions with YAML's `|2-` multi-line prefix.
      items:
        - title: Ph.D. Student
          company: "**Hong Kong University of Science and Technology (HKUST)**"
          company_url: 'https://hkust.edu.hk/'
          company_logo: 'hkust'
          location: Hong Kong
          date_start: '2023-09-01'
          date_end: ''
          description: '
          - [Department of Electronic & Computer Engineering (ECE)](https://ece.hkust.edu.hk/) and [Center for Artificial Intelligence Research (CAiRE)](https://caire.hkust.edu.hk/)

          ---

          Supervisor: [Prof. Pascale Fung](https://pascale.home.ece.ust.hk/about.html) (冯雁)
          '

        - title: Research Intern
          company: "**Xiaobing.AI (XiaoIce/小冰)**"
          company_url: 'https://www.xiaoice.com/'
          company_logo: ''
          location: 'Beijing'
          date_start: '2023-03-01'
          date_end: '2023-09-01'
          description: '
          Research Projects:
          
          - [Visual Instruction Tuning with Polite Flamingo](https://arxiv.org/abs/2307.01003). arXiv Preprint.
          
          - [Instruct Flamingo: Codebase and Fondation Models for Visual Instruction Tuning](https://github.com/ChenDelong1999/instruct-flamingo). Open Source Project.

          - [Taming Diffusion Models for Music-driven Conducting Motion Generation](https://arxiv.org/abs/2306.10065). AAAI 2023 Inaugural Summer Symposium Series - AI x Metaverse (Best Paper).

          ---

          Mentors: [Baoyuan Wang](https://sites.google.com/site/zjuwby/) (王宝元), [Jianfeng Liu](https://www.linkedin.com/in/jianfeng-liu-9539897b/) (刘剑锋) 
          '
        
        - title: Research Intern
          company: "**Megvii Research (旷视研究院)**"
          company_url: 'https://en.megvii.com/'
          company_logo: 'megvii'
          location: Beijing
          date_start: '2021-09-01'
          date_end: '2022-09-01'
          description: '
          Research Project:

          - [ProtoCILP: Prototypical Contrastive Language Image Pretraining](https://arxiv.org/abs/2206.10996). arXiv Preprint.


          ---

          Mentors: [Yiping Bao](https://scholar.google.com/citations?hl=zh-CN&user=EB9_W4kAAAAJ) (鲍一平), [Zhao Wu](https://scholar.google.com/citations?hl=zh-CN&user=rhIsGusAAAAJ) (吴曌) 
          '

        - title: Research Assistant
          company: "**AIM Group, Hohai University (河海大学多模态人工智能实验室)**"
          company_url: 'https://multimodality.group'
          company_logo: 'hhu'
          location: Nanjing (Remote)
          date_start: '2021-09-01'
          date_end: '2023-09-01'
          description: '
          
          
          Vision-language Learning:
            
            - [RemoteCLIP: A Vision Language Foundation Model for Remote Sensing](https://arxiv.org/pdf/2306.11029). arXiv Preprint.
            
            - [MEP-3M: A Large-scale Multi-modal E-Commerce Products Dataset](https://www.sciencedirect.com/science/article/pii/S0031320323002194). Pattern Recognition.


          <br/>          
          Few-shot Learning:

            - [Few-shot classification guided by generalization error bound](https://www.sciencedirect.com/science/article/pii/S0031320323006027). Pattern Recognition.

            - [Few-shot Classification via Ensemble Learning with Multi-Order Statistics](https://arxiv.org/pdf/2305.00454). IJCAI-23 (oral).



          <br/>          
          AI for Hydro-Science:

            - [A Simple Baseline for Adversarial Domain Adaptation-based Unsupervised Flood Forecasting](https://arxiv.org/pdf/2206.08105). arXiv Preprint.

            - [Asymmetric exponential loss function for crack segmentation](https://link.springer.com/article/10.1007/s00530-022-00944-4). Multimedia Systems.

            - [Significant Wave Height Prediction based on Wavelet Graph Neural Network](https://ieeexplore.ieee.org/iel7/9515196/9515201/09515293.pdf). IEEE BDAI 2021.
          

          <br/>          
          Face Recogniztion and Analysis:
          
            - [Deep Learning based Single Sample Face Recognition: a Survey](https://link.springer.com/article/10.1007/s10462-022-10240-2). Artificial Intelligence Review.

            - [A Review of Driver Fatigue Detection and Its Advances on the Use of RGB-D Camera and Deep Learning](https://www.sciencedirect.com/science/article/pii/S0952197622003967). Engineering Applications of Artificial Intelligence.
          

          ---

          Supervisor: [Prof. Fan Liu](https://multimodality.group/author/%E5%88%98%E5%87%A1/)(刘凡) 
        '
        - title: Orchestra Leader and Concert Master
          company: "**Symphony Orchestra of Hohai University (河海大学管弦乐团)**"
          company_url: ''
          company_logo: hhu
          location: Nanjing
          date_start: '2019-05-01'
          date_end: '2020-09-01'
          description: 

        - title: Summer Program
          company: "**The University of British Columbia (UBC)**"
          company_url: 'https://www.ubc.ca/'
          company_logo: 'ubc'
          location: Vancuver, Canada
          date_start: '2018-07-15'
          date_end: '2021-08-15'
          description: |2-
              Courses：
              * Computation for Natural Language Processing (scored 97/100)
              * Linguistics for Natural Language Processing (scored 85/100)

        - title: Undergraduate Study (Computer Science)
          company: "**Hohai University (河海大学)**"
          company_url: 'https://en.hhu.edu.cn/'
          company_logo: 'hhu'
          location: Nanjing
          date_start: '2017-09-01'
          date_end: '2021-06-01'
          description: '          

            Thesis Project: 

            - [《基于动态频域分解与跨模态感知的乐队指挥动作生成系统》](uploads/陈德龙本科毕业论文_基于动态频域分解与自监督跨模态感知的乐队指挥动作生成.pdf). 河海大学优秀毕业论文, 江苏省优秀本科毕业论文一等奖. (Outstanding Graduation Thesis of HHU, First-class Outstanding Graduation Thesis of Jiangsu Province)

            - [VirtualConductor: Music-driven Conducting Video Generation System](https://arxiv.org/abs/2108.04350). ICME 2021 (Best Demo Award).

            - [Self-Supervised Music Motion Synchronization Learning for Music-Driven Conducting Motion Generation](https://link.springer.com/content/pdf/10.1007/s11390-022-2030-z.pdf). Journal of Computer Science and Technology.

            '
    design:
      columns: '2'
  # - block: accomplishments
  #   content:
  #     # Note: `&shy;` is used to add a 'soft' hyphen in a long heading.
  #     title: 'Accomplish&shy;ments'
  #     subtitle:
  #     # Date format: https://wowchemy.com/docs/customization/#date-format
  #     date_format: Jan 2006
  #     # Accomplishments.
  #     #   Add/remove as many `item` blocks below as you like.
  #     #   `title`, `organization`, and `date_start` are the required parameters.
  #     #   Leave other parameters empty if not required.
  #     #   Begin multi-line descriptions with YAML's `|2-` multi-line prefix.
  #     items:
  #       - certificate_url: https://www.coursera.org
  #         date_end: ''
  #         date_start: '2021-01-25'
  #         description: ''
  #         organization: Coursera
  #         organization_url: https://www.coursera.org
  #         title: Neural Networks and Deep Learning
  #         url: ''
  #       - certificate_url: https://www.edx.org
  #         date_end: ''
  #         date_start: '2021-01-01'
  #         description: Formulated informed blockchain models, hypotheses, and use cases.
  #         organization: edX
  #         organization_url: https://www.edx.org
  #         title: Blockchain Fundamentals
  #         url: https://www.edx.org/professional-certificate/uc-berkeleyx-blockchain-fundamentals
  #       - certificate_url: https://www.datacamp.com
  #         date_end: '2020-12-21'
  #         date_start: '2020-07-01'
  #         description: ''
  #         organization: DataCamp
  #         organization_url: https://www.datacamp.com
  #         title: 'Object-Oriented Programming in R'
  #         url: ''
  #   design:
  #     columns: '2'
  # - block: collection
  #   id: posts
  #   content:
  #     title: Recent Posts
  #     subtitle: ''
  #     text: ''
  #     # Choose how many pages you would like to display (0 = all pages)
  #     count: 5
  #     # Filter on criteria
  #     filters:
  #       folders:
  #         - post
  #       author: ""
  #       category: ""
  #       tag: ""
  #       exclude_featured: false
  #       exclude_future: false
  #       exclude_past: false
  #       publication_type: ""
  #     # Choose how many pages you would like to offset by
  #     offset: 0
  #     # Page order: descending (desc) or ascending (asc) date.
  #     order: desc
  #   design:
  #     # Choose a layout view
  #     view: compact
  #     columns: '2'
  - block: markdown
    id: awards
    content:
      title: Awards✨ 
      subtitle: ''
      text: '

- **2023-01**.  **Best Paper Award** at AAAI 2023 Inaugural Summer Symposium Series - AI x Metaverse

- **2022-06**.  **江苏省优秀本科毕业论文一等奖** First Class Outstanding Graduation Thesis of Jiangsu Province

- **2021-08**. 	**Best Dataset Paper Award** at Long-Tailed Distribution Learning Workshop, IJCAI 2021

- **2021-07**. 	**Best Demo Award**  at IEEE International Conference on Multimedia and Expo (ICME) 2021

- **2021-07**. 	**Best Presentation Winner**  at 2021 4th International Conference on Big Data and Artificial Intelligence

- **2021-06**. 	**河海大学2021届本科优秀毕业设计** Outstanding Graduation Thesis of Hohai University in 2021

- **2021-06**.  **河海大学2021届本科“优秀毕业生”荣誉称号** Excellent Graduate Student of Hohai University (highest honor)

- **2021-04**.  **2020江苏省大学生网络文化节校园歌曲作品征集一等奖** First Prize in 2020 Campus Music Competition of Jiangsu Province

- **2020-05**. 	**“江苏省优秀共青团员”称号** Excellent Communist Youth League Member of Jiangsu Province

- **2020-10**. 	**“2019江苏省大学生年度人物”提名奖** Nomination Award for the Person of the Year in Jiangsu Province in 2019

- **2020-04**. 	**2020年河海大学“海韵风华大学生年度人物”称号** Hohai University 2019 Undergraduate Person of the Year

- **2019-06**. 	**第八届“中国软件杯”大学生软件设计大赛华东分赛区决赛三等奖** （团队负责人） Third Prize of The 8th China Software Cup (East China Division Finals)

- **2017-10**. 	**河海大学计算机与信息学院2017年新生杯辩论赛“最佳辩手”称号** Best Debater in the 2017 Freshman Cup Debate Competition at Hohai University

'
    design:
      # Choose a layout view
      view: 4
      columns: '1'
  - block: portfolio
    id: music
    content:
      title: Music 🎻
      subtitle: ''
      filters:
        folders:
          - project
      # Default filter index (e.g. 0 corresponds to the first `filter_button` instance below).
      default_button_index: 0
      # Filter toolbar (optional).
      # Add or remove as many filters (`filter_button` instances) as you like.
      # To show all items, set `tag` to "*".
      # To filter by a specific tag, set `tag` to an existing tag name.
      # To remove the toolbar, delete the entire `filter_button` block.
      # buttons:
      #   - name: All
      #     tag: '*'
      #   - name: Deep Learning
      #     tag: Deep Learning
      #   - name: Other
      #     tag: Demo
    design:
      # Choose how many columns the section has. Valid values: '1' or '2'.
      columns: '1'
      view: 0
      # For Showcase view, flip alternate rows?
      flip_alt_rows: false
  - block: markdown
    id: gallery
    content:
      title: Gallery 📸
      subtitle: ''
      text: |-
        {{< gallery album="demo" order="desc">}}
    design:
      columns: '1'
  # - block: collection
  #   id: talks
  #   content:
  #     title: Recent & Upcoming Talks
  #     filters:
  #       folders:
  #         - event
  #   design:
  #     columns: '2'
  #     view: compact
  # - block: tag_cloud
  #   content:
  #     title: Popular Topics
  #   design:
  #     columns: '2'
  # - block: contact
  #   id: contact
  #   content:
  #     title: Contact
  #     subtitle:
  #     text: |-
  #       Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam mi diam, venenatis ut magna et, vehicula efficitur enim.
  #     # Contact (add or remove contact options as necessary)
  #     email: test@example.org
  #     phone: 888 888 88 88
  #     appointment_url: 'https://calendly.com'
  #     address:
  #       street: 450 Serra Mall
  #       city: Stanford
  #       region: CA
  #       postcode: '94305'
  #       country: United States
  #       country_code: US
  #     directions: Enter Building 1 and take the stairs to Office 200 on Floor 2
  #     office_hours:
  #       - 'Monday 10:00 to 13:00'
  #       - 'Wednesday 09:00 to 10:00'
  #     contact_links:
  #       - icon: twitter
  #         icon_pack: fab
  #         name: DM Me
  #         link: 'https://twitter.com/Twitter'
  #       - icon: skype
  #         icon_pack: fab
  #         name: Skype Me
  #         link: 'skype:echo123?call'
  #       - icon: video
  #         icon_pack: fas
  #         name: Zoom Me
  #         link: 'https://zoom.com'
  #     # Automatically link email and phone or display as text?
  #     autolink: true
  #     # Email form provider
  #     form:
  #       provider: netlify
  #       formspree:
  #         id:
  #       netlify:
  #         # Enable CAPTCHA challenge to reduce spam?
  #         captcha: false
  #   design:
  #     columns: '2'
---
